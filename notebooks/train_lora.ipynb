{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5658e08-3c3b-4927-a522-a2cf83c06e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb68750b-b6e9-4787-8bf4-6869673d299c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd = \"\"\"\n",
    "python /home/jupyter/ShareGPT4V/share4v/train/train.py \\\n",
    "    --model_name_or_path \"Lin-Chen/ShareGPT4V-7B\" \\\n",
    "    --version \"vicuna_v1\" \\  # Or other appropriate conversation template version\n",
    "    --data_path \"path/to/your/training_data.json\" \\\n",
    "    --output_dir \"path/to/your/output_lora_adapters\" \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --learning_rate 2e-4 \\ # This LR will be for any non-LoRA params if tuned. LoRA params scale with alpha/r.\n",
    "    --weight_decay 0. \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --tf32 False \\ # Set to True if using Ampere GPUs or newer for speed\n",
    "    --bf16 True \\  # Or --fp16 True, depending on your hardware. BF16 is generally preferred.\n",
    "    --model_max_length 2048 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --lazy_preprocess True \\\n",
    "    \\\n",
    "    # --- LoRA Specific Arguments ---\n",
    "    --lora_enable True \\\n",
    "    --lora_r 64 \\\n",
    "    --lora_alpha 16 \\ # Or lora_r value\n",
    "    --lora_dropout 0.05 \\\n",
    "    # --lora_bias \"none\" # Default is \"none\"\n",
    "    \\\n",
    "    # --- Multimodal Specific Arguments (if applicable) ---\n",
    "    --vision_tower \"path/to/your/vision_tower_e.g._openai/clip-vit-large-patch14-336\" \\\n",
    "    --image_folder \"path/to/your/images\" \\\n",
    "    --is_multimodal True \\\n",
    "    --image_aspect_ratio 'square' \\ # Or 'pad'\n",
    "    --mm_projector_type 'mlp2x_gelu' \\ # Or other projector type\n",
    "    --tune_mm_mlp_adapter True \\ # Option to tune the projector alongside LoRA\n",
    "    # --tune_vision_tower True # Option to tune the vision tower (can be memory intensive)\n",
    "    # --vision_tower_lr 2e-5 # If tuning vision tower, specify its LR\n",
    "    # --mm_projector_lr 2e-5 # If tuning MLP adapter, specify its LR\n",
    "    \\\n",
    "    # --- QLoRA Specific Arguments (if using quantization) ---\n",
    "    # --bits 4 \\\n",
    "    # --double_quant True \\\n",
    "    # --quant_type \"nf4\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7696d2bc-d36f-4c64-8711-c8d1cc7badc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = cmd.split(\"    \")\n",
    "lines = [\n",
    "    re.sub(r\"\\s*#.*\", \"\", l).strip().strip(\"\\\\\").strip()\n",
    "    for l in lines\n",
    "]\n",
    "lines = [l for l in lines if l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b95d1a7-1a49-4d26-9896-5ac64147652d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!python /home/jupyter/ShareGPT4V/share4v/train/train.py \\\n",
      "    --model_name_or_path \"Lin-Chen/ShareGPT4V-7B\" \\\n",
      "    --version \"vicuna_v1\" \\\n",
      "    --data_path \"path/to/your/training_data.json\" \\\n",
      "    --output_dir \"path/to/your/output_lora_adapters\" \\\n",
      "    --num_train_epochs 3 \\\n",
      "    --per_device_train_batch_size 2 \\\n",
      "    --gradient_accumulation_steps 8 \\\n",
      "    --learning_rate 2e-4 \\\n",
      "    --weight_decay 0. \\\n",
      "    --warmup_ratio 0.03 \\\n",
      "    --lr_scheduler_type \"cosine\" \\\n",
      "    --logging_steps 1 \\\n",
      "    --tf32 False \\\n",
      "    --bf16 True \\\n",
      "    --model_max_length 2048 \\\n",
      "    --gradient_checkpointing True \\\n",
      "    --lazy_preprocess True \\\n",
      "    --lora_enable True \\\n",
      "    --lora_r 64 \\\n",
      "    --lora_alpha 16 \\\n",
      "    --lora_dropout 0.05 \\\n",
      "    --vision_tower \"path/to/your/vision_tower_e.g._openai/clip-vit-large-patch14-336\" \\\n",
      "    --image_folder \"path/to/your/images\" \\\n",
      "    --is_multimodal True \\\n",
      "    --image_aspect_ratio 'square' \\\n",
      "    --mm_projector_type 'mlp2x_gelu' \\\n",
      "    --tune_mm_mlp_adapter True\n"
     ]
    }
   ],
   "source": [
    "print(\"!\" + \" \\\\\\n    \".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a074194-f8af-44a2-bf43-21a004e47aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.cache/pypoetry/virtualenvs/share4v-KfdsAbnj-py3.10/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/home/jupyter/.cache/pypoetry/virtualenvs/share4v-KfdsAbnj-py3.10/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "/home/jupyter/.cache/pypoetry/virtualenvs/share4v-KfdsAbnj-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "!python /home/jupyter/ShareGPT4V/share4v/train/train.py \\\n",
    "    --model_name_or_path \"Lin-Chen/ShareGPT4V-7B\" \\\n",
    "    --version \"vicuna_v1\" \\\n",
    "    --data_path \"path/to/your/training_data.json\" \\\n",
    "    --output_dir \"path/to/your/output_lora_adapters\" \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --learning_rate 2e-4 \\\n",
    "    --weight_decay 0. \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --tf32 False \\\n",
    "    --bf16 True \\\n",
    "    --model_max_length 2048 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --lazy_preprocess True \\\n",
    "    --lora_enable True \\\n",
    "    --lora_r 64 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --vision_tower \"Lin-Chen/ShareGPT4V-7B_Pretrained_vit-large336-l12\" \\\n",
    "    --image_folder \"path/to/your/images\" \\\n",
    "    --is_multimodal True \\\n",
    "    --image_aspect_ratio 'square' \\\n",
    "    --mm_projector_type 'mlp2x_gelu' \\\n",
    "    --tune_mm_mlp_adapter True"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-poetry-kernel",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "conda-base-poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
